# Natural Language Processing with Probabilistic Models
## DeepLearning.AI

#### W1 Auto Correct
* Autocorrect, minimum edit distance, and dynamic programming, spellchecker to correct misspelled words!

#### W2 Part of Speech Tagging and Hidden Markov Models, Viterbi Algorithm
*  Part-of-speech tags for a Wall Street Journal text corpus!

#### W3 Autocomplete and Language Models
*  How N-gram language models work by calculating sequence probabilities,  build autocomplete language model using a text corpus from Twitter!

#### W4 Word embeddings with neural networks
* Semantic meaning of words by word embeddings, build Continuous bag-of-words model to create word embeddings from Shakespeare text.
